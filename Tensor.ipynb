{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensor.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMgsoPKtxdmw+FWKCdW5d2K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fruktwow/g_colab/blob/main/Tensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4kIh55FI_8n",
        "outputId": "6014c262-a810-4145-f924-875f71f51d6a"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "X = torch.tensor([1.0, 2.0, 3.0])\n",
        "Y = torch.tensor([2.0, 4.0, 6.0])\n",
        "\n",
        "w1 = torch.tensor([0.2], requires_grad=True)  \n",
        "w2 = torch.tensor([0.4], requires_grad=True)\n",
        "wb = torch.tensor([1.0], requires_grad=True)\n",
        "\n",
        "# our model forward pass\n",
        "def forward(x):\n",
        "  return ((pow(x,2) * w2) + (x * w1) + wb)\n",
        "\n",
        "# mse loss function\n",
        "lf= F.mse_loss\n",
        "\n",
        "\n",
        "# Before training\n",
        "print(\"predict (before training)\",  4, forward(2000))\n",
        "\n",
        " \n",
        "lr = 0.0000000000000001\n",
        "# Training loop \n",
        "for epoch in range(100):\n",
        "  for x1, y1 in zip(X, Y): \n",
        "    y_pred = forward(x1)\n",
        "    l = lf(y_pred, y1)\n",
        "    l.backward()  \n",
        "    with torch.no_grad():\n",
        "      w1-= lr * w1.grad\n",
        "      w2-= lr * w2.grad\n",
        "      wb-= lr * wb.grad      \n",
        "      print(\"\\tgrad: \", x1, y1, w1.grad.item(),w2.grad.item(),b.grad.item())\n",
        "  #updating the gradients to zero after updating\n",
        "  w1.grad.zero_()\n",
        "  w2.grad.zero_()\n",
        "  wb.grad.zero_()\n",
        "  print(\"progress:\", epoch, \"w1=\", w1, \"w2=\",w2, \"l=\", l, \"b=\",wb) \n",
        "  \n",
        "# After training\n",
        "print(\"predict (after training)\",  \"4 hours\", forward(2000))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict (before training) 4 tensor([1600401.], grad_fn=<AddBackward0>)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 0 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 1 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 2 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 3 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 4 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 5 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 6 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 7 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 8 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 9 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 10 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 11 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 12 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 13 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 14 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 15 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 16 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 17 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 18 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 19 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 20 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 21 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 22 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 23 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 24 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 25 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 26 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 27 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 28 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 29 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 30 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 31 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 32 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 33 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 34 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 35 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 36 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 37 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 38 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 39 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 40 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 41 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 42 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 43 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 44 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 45 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 46 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 47 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 48 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 49 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 50 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 51 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 52 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 53 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 54 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 55 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 56 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 57 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 58 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 59 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 60 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 61 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 62 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 63 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 64 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 65 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 66 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 67 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 68 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 69 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 70 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 71 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 72 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 73 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 74 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 75 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 76 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 77 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 78 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 79 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 80 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 81 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 82 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 83 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 84 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 85 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 86 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 87 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 88 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 89 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 90 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 91 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 92 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 93 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 94 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 95 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 96 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 97 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 98 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "\tgrad:  tensor(1.) tensor(2.) -0.7999999523162842 -0.7999999523162842 0.0\n",
            "\tgrad:  tensor(2.) tensor(4.) -4.800000190734863 -8.800000190734863 0.0\n",
            "\tgrad:  tensor(3.) tensor(6.) -9.599998474121094 -23.199995040893555 0.0\n",
            "progress: 99 w1= tensor([0.2000], requires_grad=True) w2= tensor([0.4000], requires_grad=True) l= tensor(0.6400, grad_fn=<MseLossBackward>) b= tensor([1.], requires_grad=True)\n",
            "predict (after training) 4 hours tensor([1600401.], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}